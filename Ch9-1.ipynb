{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**순환 신경망(Recurrent Neural Network)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "완전 연결 신경망 + 데이터의 처리 흐름 순환 고리\n",
    "\n",
    "**타임스텝(timestep)** : 샘플을 처리하는 한 단계\n",
    "\n",
    "순환 신경망은 이전 타임스텝의 샘플을 기억하지만 타임스텝이 오래될수록 순환되는 정보는 희미해짐\n",
    "\n",
    "**셀(Cell)** : 순환 신경망에서 층\n",
    "\n",
    "한 셀에는 여러 개의 뉴런이 있지만 완전 연결 신경망과 달리 뉴런을 모두 표시하지 않고 하나의 셀로 층을 표현\n",
    "\n",
    "**은닉상태(hidden state)** : 셀의 출력\n",
    "\n",
    "기본 구조 : 입력에 어떤 가중치를 곱하고 활성화 함수를 통과시켜 다음 층으로 전달. \n",
    "층의 출력(은닉상태)을 다음 타임스텝에 재사용\n",
    "\n",
    "은닉층의 활성화 함수로 주로 **하이퍼볼릭 탄젠트(hyperbolic tagent) : tanh**를 주로 사용\n",
    "\n",
    "피드포워드 신경망(합성곱 신경망 등)에서 뉴런은 입력과 가중치를 곱함\n",
    "\n",
    "순환 신경망의 뉴런은 가중치가 하나 더 존재 = 이전 타임스텝의 은닉 상태에 곱해지는 가중치\n",
    "\n",
    "셀은 입력과 이전 타임스텝의 은닉 상태를 사용 ==> 현재 타임스텝의 은닉 상태를 만듦\n",
    "\n",
    "타임스텝에서 사용되는 가중치는 w_h 하나만 존재\n",
    "\n",
    "가중치 w_h는 타임스텝에 따라 변화되는 뉴런의 출력을 학습\n",
    "\n",
    "타임스텝 1에서 사용되는 이전 은닉상태 h_0 = 0 : 이전 타임스텝이 없으므로\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. 셀의 가중치와 입출력**\n",
    "\n",
    "입력되는 특성 4, 순환층 뉴런 3일 때, w_x의 크기는 (입력층 특성 x 순환층 뉴런) 4x3 = 12\n",
    "\n",
    "순환층에서 다음 타임스텝에 재사용되는 은닉 상태를 위한 가중치 w_h의 크기 = (은닉층의 개수 x 은닉층의 개수) 3x3 = 9\n",
    "\n",
    "모델 파라미터 개수 : 가중치 + 절편 ; 각 뉴런마다 하나의 절편 존재 ==> 이 순환층은 모두 12 + 9 + 3 = 24개의 파라미터 존재\n",
    "\n",
    "[델 파라미터 수 = w_x + w_h + 절편 = 12 + 9 + 3 = 24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. 순환층의 입력과 출력**\n",
    "\n",
    "합성곱 층의 입력은 하나의 샘플이 3개의 차원(너비, 높이, 채널)을 가짐\n",
    "\n",
    "입력이 합성곱 층과 풀링 층을 통과하면 너비, 높이, 채널(혹은 깊이)의 크기가 달라지지만 차원의 개수는 그대로 유지\n",
    "\n",
    "순환층은 일반적으로 샘플마다 2개의 차원을 가짐.\n",
    "\n",
    "**sequence** : 하나의 샘플\n",
    "\n",
    "시퀀스 안에는 여러 개의 아이템이 들어있음\n",
    "\n",
    "따라서 시퀀스의 길이 = 타임스텝의 길이\n",
    "\n",
    "Ex) \"I am a boy\"는 4개의 단어로 구성, 각 단어를 3개의 숫자로 표현한다고 가정 -> (1, 4, 3) = 타임스텝 크기\n",
    "    입력이 순환층을 통과하면, 두 번째, 세 번째 차원이 사라지고 순환층의 뉴런 개수만큼 출력 됨\n",
    "    하나의 샘플은 시퀀스 길이(단어의 개수)와 단어 표현의 2차원 배열\n",
    "    순환층을 통과하면 1차원 배열로 변환됨. 1차원 배열의 크기는 순환층의 뉴런 개수에 의해 결정\n",
    "\n",
    "**순환층은 기본적으로 마지막 타임스텝의 은닉 상태만 출력으로 내보냄**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. 출력층의 구성**\n",
    "\n",
    "마지막 층에는 **밀집층(Dense layer)**을 두어 클래스를 분류\n",
    "\n",
    "다중 분류 : 출력층에 클래스 개수만큼 뉴런을 두고 softmax 활성화 함수를 적용\n",
    "\n",
    "이진 분류 : 하나의 뉴런을 두고 sigmoid 활성화 함수를 적용\n",
    "\n",
    "합성곱 신경망과 차이점 : 마지막 셀의 출력이 1차원 ==> **Flatten 클래스**로 펼칠 필요 X\n",
    "셀의 출력을 그대로 및집층에 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f54aa211a2ccc840cc7a109aa923afcf3d1bc58be22381604782dce87486fa90"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
